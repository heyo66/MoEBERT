{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda9e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/MoEBERT/src/convert_dataset.py\", line 439, in <module>\n",
      "    main(parse_args())\n",
      "  File \"/home/user/MoEBERT/src/convert_dataset.py\", line 396, in main\n",
      "    dataset = build_hf_dataset(\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/MoEBERT/src/convert_dataset.py\", line 291, in build_hf_dataset\n",
      "    raise ValueError(tok_error_msg)\n",
      "ValueError: This tokenizer does not insert an EOS nor BOS token. Concatenating with this tokenizer will result in sequences being attached without a separating token. Please use another tokenizer, such as facebook/opt-125m, or specify EOS/BOS text with e.g. --bos_text=<|endoftext|>.\n"
     ]
    }
   ],
   "source": [
    "!python src/convert_dataset.py \\\n",
    "  --dataset c4 \\\n",
    "  --data_subset en \\\n",
    "  --splits train_small val_small \\\n",
    "  --out_root ./c4_tokenized_bert_small \\\n",
    "  --concat_tokens 512 \\\n",
    "  --tokenizer bert-base-uncased \\\n",
    "  --bos_text \"[CLS]\" \\\n",
    "  --eos_text \"[SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09965d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/user/.cache/huggingface/modules/datasets_modules/datasets/c4/584d57ebe81c209b6c7f31727066d2c4b4bba37cb7092cdd83083d5ec11207db/c4.py:53: FutureWarning: Dataset 'c4' is deprecated and will be deleted. Use 'allenai/c4' instead.\n",
      "  warnings.warn(\n",
      "/home/user/MoEBERT/src/convert_dataset.py:227: UserWarning: The provided tokenizer adds special tokens, but you also specified both eos and bos. This may result in duplicated special tokens. Please be sure this is what you intend.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 32, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Converting train_small to MDS format...\n",
      "train_small: 100%|████████████████████| 100000/100000 [00:30<00:00, 3255.12it/s]\n",
      "/home/user/.cache/huggingface/modules/datasets_modules/datasets/c4/584d57ebe81c209b6c7f31727066d2c4b4bba37cb7092cdd83083d5ec11207db/c4.py:53: FutureWarning: Dataset 'c4' is deprecated and will be deleted. Use 'allenai/c4' instead.\n",
      "  warnings.warn(\n",
      "/home/user/MoEBERT/src/convert_dataset.py:227: UserWarning: The provided tokenizer adds special tokens, but you also specified both eos and bos. This may result in duplicated special tokens. Please be sure this is what you intend.\n",
      "  warnings.warn(\n",
      "Converting val_small to MDS format...\n",
      "val_small: 100%|████████████████████████| 10000/10000 [00:03<00:00, 2612.44it/s]\n"
     ]
    }
   ],
   "source": [
    "!python src/convert_dataset.py \\\n",
    "  --dataset c4 \\\n",
    "  --data_subset en \\\n",
    "  --splits train_small val_small \\\n",
    "  --out_root ./c4_tokenized_bert_small \\\n",
    "  --concat_tokens 512 \\\n",
    "  --tokenizer bert-base-uncased \\\n",
    "  --bos_text \"[CLS]\" \\\n",
    "  --eos_text \"[SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e9d8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/.cache/huggingface/modules/datasets_modules/datasets/c4/584d57ebe81c209b6c7f31727066d2c4b4bba37cb7092cdd83083d5ec11207db/c4.py:53: FutureWarning: Dataset 'c4' is deprecated and will be deleted. Use 'allenai/c4' instead.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 32, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Converting train_small to MDS format...\n",
      "train_small: 100%|████████████████████| 100000/100000 [00:12<00:00, 7947.34it/s]\n",
      "/home/user/.cache/huggingface/modules/datasets_modules/datasets/c4/584d57ebe81c209b6c7f31727066d2c4b4bba37cb7092cdd83083d5ec11207db/c4.py:53: FutureWarning: Dataset 'c4' is deprecated and will be deleted. Use 'allenai/c4' instead.\n",
      "  warnings.warn(\n",
      "Converting val_small to MDS format...\n",
      "val_small: 100%|████████████████████████| 10000/10000 [00:02<00:00, 4574.10it/s]\n"
     ]
    }
   ],
   "source": [
    "!python src/convert_dataset.py \\\n",
    "  --dataset c4 \\\n",
    "  --data_subset en \\\n",
    "  --splits train_small val_small \\\n",
    "  --out_root ./c4_small "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e54eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/.cache/huggingface/modules/datasets_modules/datasets/c4/584d57ebe81c209b6c7f31727066d2c4b4bba37cb7092cdd83083d5ec11207db/c4.py:53: FutureWarning: Dataset 'c4' is deprecated and will be deleted. Use 'allenai/c4' instead.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 32, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Converting train to MDS format...\n",
      "train:   4%|▋                 | 13295104/364868892 [03:49<1:41:06, 57953.03it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/MoEBERT/src/convert_dataset.py\", line 439, in <module>\n",
      "    main(parse_args())\n",
      "  File \"/home/user/MoEBERT/src/convert_dataset.py\", line 431, in main\n",
      "    for sample in tqdm(samples, desc=folder_split, total=denominator):\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/home/user/MoEBERT/src/convert_dataset.py\", line 348, in generate_samples\n",
      "    for batch in loader:\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1324, in _next_data\n",
      "    return self._process_data(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1370, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/torch/_utils.py\", line 706, in reraise\n",
      "    raise exception\n",
      "huggingface_hub.utils._errors.HfHubHTTPError: Caught HfHubHTTPError in DataLoader worker process 47.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/huggingface_hub-0.24.6-py3.8.egg/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/requests/models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/datasets/allenai/c4/resolve/1ddc917116b730e1859edef32896ec5c16be51d0/realnewslike/c4-train.00495-of-00512.json.gz\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 33, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/MoEBERT/src/convert_dataset.py\", line 153, in __iter__\n",
      "    for sample in self.hf_dataset:\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/datasets/iterable_dataset.py\", line 2011, in __iter__\n",
      "    yield from self._iter_pytorch()\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/datasets/iterable_dataset.py\", line 1936, in _iter_pytorch\n",
      "    for key, example in ex_iterable:\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/datasets/iterable_dataset.py\", line 189, in __iter__\n",
      "    for key_example in islice(self.generate_examples_fn(**gen_kwags), shard_example_idx_start, None):\n",
      "  File \"/home/user/.cache/huggingface/modules/datasets_modules/datasets/c4/584d57ebe81c209b6c7f31727066d2c4b4bba37cb7092cdd83083d5ec11207db/c4.py\", line 94, in _generate_examples\n",
      "    for line in f:\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/gzip.py\", line 314, in read1\n",
      "    return self._buffer.read1(size)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/_compression.py\", line 68, in readinto\n",
      "    data = self.read(len(byte_view))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/gzip.py\", line 505, in read\n",
      "    buf = self._fp.read(io.DEFAULT_BUFFER_SIZE)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/gzip.py\", line 97, in read\n",
      "    self.file.read(size-self._length+read)\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/datasets/utils/file_utils.py\", line 1117, in read_with_retries\n",
      "    out = read(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/huggingface_hub-0.24.6-py3.8.egg/huggingface_hub/hf_file_system.py\", line 765, in read\n",
      "    return super().read(length)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/fsspec/spec.py\", line 1941, in read\n",
      "    out = self.cache._fetch(self.loc, self.loc + length)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/fsspec/caching.py\", line 234, in _fetch\n",
      "    self.cache = self.fetcher(start, end)  # new block replaces old\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/huggingface_hub-0.24.6-py3.8.egg/huggingface_hub/hf_file_system.py\", line 728, in _fetch_range\n",
      "    hf_raise_for_status(r)\n",
      "  File \"/home/user/miniconda3/envs/bert24/lib/python3.11/site-packages/huggingface_hub-0.24.6-py3.8.egg/huggingface_hub/utils/_errors.py\", line 371, in hf_raise_for_status\n",
      "    raise HfHubHTTPError(str(e), response=response) from e\n",
      "huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/datasets/allenai/c4/resolve/1ddc917116b730e1859edef32896ec5c16be51d0/realnewslike/c4-train.00495-of-00512.json.gz (Request ID: Root=1-693d6042-18fe64637f6cfa9b676ed9a2;d5fe046c-06ec-4b3a-8035-4faf6ccd9662)\n",
      "\n",
      "We had to rate limit your IP (194.95.16.142). To continue using our service, create a HF account or login to your existing account, and make sure you pass a HF_TOKEN if you're using the API.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python src/convert_dataset.py \\\n",
    "  --dataset c4 \\\n",
    "  --data_subset realnewslike \\\n",
    "  --splits train val \\\n",
    "  --out_root ./c4_realnewslike\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
